<p align="center">
<strong>=================================================================</strong><br>
<strong>機能設計書</strong><br><br>
<strong>日付:</strong> 10/2025<br><br>
<strong>モデレーター:</strong> Daniel.J.Q.Goh<br>
<strong>=================================================================</strong>
</p>

<br><br><br><br>

---

## Raspberry Pi用リアルタイム物体検出システム

### 文書情報
- **プロジェクト**: リアルタイム人物検出システム
- **バージョン**: 1.0
- **日付**: 2025年10月14日
- **著者**: Daniel.J.Q.GOH
- **ステータス**: ドラフト

---

## 概要

この文書は、Raspberry Piデバイス用に特別に最適化されたリアルタイム物体検出システムの機能設計について説明します。システムは、YOLOv11（You Only Look Once）ニューラルネットワークアーキテクチャを使用して、ライブカメラフィードで人物を検出し、スマート表示モード切り替えとパフォーマンス最適化を提供します。

### 主要機能
- YOLOv11を使用したリアルタイム人物検出
- NCNN形式によるRaspberry Piハードウェア最適化
- より高速で軽量な推論のためのPyTorch→ONNX モデル変換
- スマートカメラ検出と設定
- 適応表示モード（GUI/ヘッドレス）
- パフォーマンス監視と統計
- 画像キャプチャと保存機能

---

<div style="page-break-after: always;"></div>

## 1. システム概要

### 1.1 目的
リソース制約のあるRaspberry Piハードウェア上で、監視、モニタリング、または研究アプリケーション向けのリアルタイム人物検出機能を提供するシステムです。

### 1.2 スコープ
- **主要機能**: リアルタイムビデオストリームでの人物検出と計数
- **対象プラットフォーム**: Raspberry Pi（カメラサポート付きの全モデル）
- **検出モデル**: YOLOv11 nano（軽量バリアント）
- **入力ソース**: USBウェブカメラ、Piカメラモジュール
- **出力**: 視覚的注釈、統計、保存画像

### 1.3 アーキテクチャ概要
```
┌─────────────────┐       ┌──────────────────┐      ┌─────────────────┐
    Camera Input    ───▶     Detection Core    ───▶   Output Handler 
└─────────────────┘       └──────────────────┘      └─────────────────┘
         │                         │                         │
         ▼                         ▼                         ▼
┌─────────────────┐       ┌──────────────────┐      ┌─────────────────┐
│ • USB Webcam    │       │ • YOLOv11 Model  │      │ • GUI Display   │
│ • Pi Camera     │       │ • PyTorch→ONNX   │      │ • Image Saving  │
│ • Auto-detect   │       │ • NCNN Optimize  │      │ • Statistics    │
│                 │       │ • People Filter  │      │                 │
└─────────────────┘       └──────────────────┘      └─────────────────┘
```

---

<div style="page-break-after: always;"></div>

## 2. 機能要件

### 2.1 コア検出機能

#### 2.1.1 人物検出
- **機能**: ビデオフレーム内の人間の姿を検出
- **入力**: ビデオフレーム（640x480 BGR）
- **出力**: 信頼度スコア付きバウンディングボックス
- **パフォーマンス**: Raspberry Pi 3B V1.2で最低5 FPS
- **精度**: 明確に見える人物に対して90%以上の精度

#### 2.1.2 リアルタイム処理
- **機能**: ビデオストリームを継続的に処理
- **遅延**: フレームあたり200ms未満
- **バッファ管理**: 遅延を減らすための単一フレームバッファ
- **フレームレート**: 適応的（ハードウェアに基づいて5-15 FPS）

#### 2.1.3 信頼度フィルタリング
- **機能**: 信頼度閾値に基づく検出のフィルタリング
- **デフォルト閾値**: 0.5（50%）
- **設定可能**: はい、実行時調整可能
- **目的**: 偽陽性の削減

### 2.2 ハードウェアインターフェース機能

#### 2.2.1 カメラ検出
- **機能**: 利用可能なカメラを自動検出
- **スキャン範囲**: カメラインデックス0-3
- **検証**: フレームキャプチャ機能のテスト
- **フォールバック**: 優先カメラが利用できない場合は最初の利用可能なカメラを使用

#### 2.2.2 カメラ設定
- **機能**: パフォーマンス向けカメラ設定の最適化
- **解像度**: 640x480（設定可能）
- **フレームレート**: 15 FPS目標
- **バッファサイズ**: 1フレーム（遅延最小化）

#### 2.2.3 プラットフォーム検出
- **機能**: Raspberry Pi上で動作しているかを識別
- **方法**: `/proc/device-tree/model`をチェック
- **目的**: Pi固有の最適化を有効化
- **フォールバック**: 他のプラットフォーム用汎用モード

### 2.3 表示と出力機能

#### 2.3.1 スマート表示モード
- **機能**: 適切な表示モードを自動選択
- **GUIモード**: 表示環境が利用可能な場合
- **ヘッドレスモード**: 表示なし（SSH、ヘッドレス設定）
- **検出**: DISPLAY環境変数をチェック

#### 2.3.2 視覚的注釈
- **機能**: フレームに検出結果を描画
- **バウンディングボックス**: 検出された人物の周りの赤い矩形
- **ラベル**: 信頼度スコア付き緑色テキスト
- **オーバーレイ情報**: FPS、人数、カメラインデックス

#### 2.3.3 画像保存
- **機能**: 注釈付きフレームをディスクに保存
- **トリガー**: 手動（'s'キー）または自動（時間間隔）
- **形式**: タイムスタンプ付きJPEG
- **命名**: `detection_[timestamp]_people_[count].jpg`

### 2.4 パフォーマンス監視

#### 2.4.1 統計追跡
- **機能**: システムパフォーマンスメトリクスの監視
- **メトリクス**: FPS、総フレーム数、検出数、実行時間
- **表示**: リアルタイムオーバーレイと最終サマリー
- **ログ**: ステータス更新付きコンソール出力

#### 2.4.2 リソース最適化
- **機能**: Raspberry Pi制約用の最適化
- **モデル形式**: PyTorch→ONNX→NCNN変換パイプライン
- **推論エンジン**: 軽量実行のためのONNX Runtime
- **メモリ管理**: 最小バッファ使用
- **処理**: 重いPyTorchランタイムなしのバッチフリー推論

---

<div style="page-break-after: always;"></div>

## 3. 技術仕様

### 3.1 依存関係と要件

#### 3.1.1 ソフトウェア依存関係
```python
# コア依存関係
opencv-python>=4.5.0      # コンピュータビジョンライブラリ
ultralytics>=11.0.0       # YOLOv11実装
numpy>=1.21.0             # 数値計算

# システム依存関係
platform                  # システム情報
time                      # タイミング機能
os                        # 環境変数
```

#### 3.1.2 ハードウェア要件
- **最小**: Raspberry Pi 3B V1.2（1GB RAM）
- **推奨**: Raspberry Pi 4（8GB以上 RAM）
- **カメラ**: USBウェブカメラまたはPiカメラモジュール
- **ストレージ**: モデルと画像用に2GB空き容量（推定）
- **オプション**: GUIモード用ディスプレイ

#### 3.1.3 オペレーティングシステム
- **主要**: Raspberry Pi OS（Debianベース）
- **互換**: Ubuntu、その他のLinuxディストリビューション
- **Python**: 3.7以上

<div style="page-break-after: always;"></div>

### 3.2 モデル仕様

#### 3.2.0 モデル最適化パイプライン
システムは、Raspberry Piハードウェアで最大パフォーマンスを実現するために3段階最適化パイプラインを採用しています：

```
PyTorch Model (.pt) → ONNX Format (.onnx) → NCNN Format (.param/.bin)
      ↓                     ↓                        ↓
  研究/訓練用            標準化形式                ARM最適化ランタイム
```

**PyTorch → ONNX変換の利点:**
- **PyTorch依存関係の排除**: 重いPyTorchランタイム（500MB以上）を除去
- **標準化形式**: ONNXはフレームワーク非依存で広くサポート
- **より良い最適化**: ONNXは高度なグラフ最適化を可能にする
- **推論エンジン**: ONNX Runtime、TensorRT、OpenCV DNNと互換
- **メモリフットプリントの削減**: より小さなモデルサイズと実行時メモリ使用量
- **高速読み込み**: PyTorchオーバーヘッドなしでより迅速なモデル初期化

**ONNX → NCNN変換の利点:**
- **ARM NEON最適化**: ARM固有のSIMD命令を活用
- **モバイルファースト設計**: モバイルと組み込みデバイス専用構築
- **最小依存関係**: 外部依存関係のない軽量ランタイム
- **量子化サポート**: さらなる速度向上のためのINT8量子化
- **マルチスレッド**: マルチコアARM CPUでの最適化並列実行

#### 3.2.1 YOLOv11設定
- **バリアント**: YOLOv11 Nano（yolov11n.pt）
- **サイズ**: 約5.8MBモデルファイル
- **クラス**: COCOデータセット（80クラス、クラス0：personにフォーカス）
- **入力サイズ**: 640x640（カメラ入力からリサイズ）
- **エクスポートパイプライン**: PyTorch（.pt）→ ONNX（.onnx）→ NCNN（.param/.bin）
- **最適化利点**: 
  - **高速推論**: PyTorchランタイムオーバーヘッドを排除
  - **軽量フットプリント**: ONNX/NCNNモデルはよりコンパクト
  - **より良い互換性**: OpenCV DNN、TensorRT、ONNX Runtime推論と連携
  - **ARM最適化**: NCNNはARM NEON加速を提供

<div style="page-break-after: always;"></div>

#### 3.2.2 検出パラメータ
- **信頼度閾値**: 0.5（設定可能）
- **NMS閾値**: 0.45（Non-Maximum Suppression）
- **最大検出数**: 無制限
- **対象クラス**: Person（COCOクラス0）

### 3.3 パフォーマンスベンチマーク

#### 3.3.2 Raspberry Pi 3B V1.2
- **期待FPS**: 5-8 FPS（ONNX最適化により向上）
- **推論時間**: フレームあたり120-200ms（PyTorchベースラインから削減）
- **メモリ使用量**: 300-500MB（PyTorchランタイムより軽量）
- **CPU使用率**: 70-85%（最適化ARM実行）

---

<div style="page-break-after: always;"></div>

## 4. システムインターフェース

### 4.1 ユーザーインターフェース

#### 4.1.1 コマンドラインインターフェース
```bash
# 基本実行
python obj_detection.py

# システムは自動的に：
# 1. プラットフォーム検出（Raspberry Piチェック）
# 2. 利用可能なカメラの発見
# 3. YOLOv11モデルの読み込みと最適化
# 4. 適切な表示モードの選択
# 5. 検出ループの開始
```

#### 4.1.2 インタラクティブ制御（GUIモード）
- **'q'キー**: アプリケーション終了
- **'s'キー**: 現在のフレームを保存
- **ESCキー**: 緊急終了
- **ウィンドウクローズ**: 標準ウィンドウ制御

#### 4.1.3 ステータス出力
```
リアルタイムコンソール出力:
- プラットフォーム検出結果
- カメラ発見とセットアップ
- モデル読み込み進行状況
- パフォーマンス統計
- 検出イベント
```

### 4.2 ハードウェアインターフェース

#### 4.2.1 カメラインターフェース
```python
# カメラ検出プロトコル
for camera_index in range(4):
    cap = cv2.VideoCapture(camera_index)
    if cap.isOpened():
        ret, frame = cap.read()
        if ret:
            # カメラは機能している
            configure_camera_settings(cap)
```

#### 4.2.2 ファイルシステムインターフェース
```
出力ファイル構造:
├── detection_[timestamp].jpg          # 手動保存
├── detection_[timestamp]_people_[n].jpg  # カウント付き自動保存
└── detection_final_[timestamp].jpg    # 最終フレーム保存
```

### 4.3 ソフトウェアインターフェース

#### 4.3.1 モデル読み込みと最適化
```python
# モデル最適化パイプライン実装
model = YOLO('yolov11n.pt')                    # PyTorchモデル読み込み
onnx_path = model.export(format='onnx')        # ONNXに変換
ncnn_path = model.export(format='ncnn')        # NCNNに変換

# ランタイム利点:
# - PyTorchと比較して3倍高速推論
# - 60%少ないメモリ使用量
# - PyTorchランタイム依存関係なし
# - ARM NEON加速有効
```

#### 4.3.2 OpenCV統合
```python
# カメラと表示統合
cap = cv2.VideoCapture(index)
cv2.imshow('Detection Window', frame)
cv2.imwrite(filename, annotated_frame)
```

---

<div style="page-break-after: always;"></div>

## 5. システム動作

### 5.1 起動シーケンス

1. **システムチェック**（2-3秒）
   - 表示環境情報の表示
   - プラットフォーム検出（Raspberry Piチェック）
   - Python/OpenCVバージョン確認

2. **モデル初期化**（5-10秒）
   - 存在しない場合YOLOv11n.ptをダウンロード
   - PyTorchモデルをONNX形式に変換
   - ONNXをNCNN形式にエクスポート
   - メモリフットプリント削減で最適化モデルを読み込み

3. **カメラセットアップ**（1-2秒）
   - 利用可能なカメラをスキャン
   - 優先カメラを選択（インデックス1、フォールバック0）
   - 最適設定を構成

4. **検出開始**（即座）
   - メイン検出ループに入る
   - リアルタイム処理開始

<div style="page-break-after: always;"></div>

### 5.2 検出ループ

```python
while True:
    # 1. カメラからフレームをキャプチャ
    ret, frame = cap.read()
    
    # 2. YOLO推論を実行
    results = model(frame)
    
    # 3. 検出を処理（人物をフィルタ）
    people_count = count_people(results)
    
    # 4. フレームに注釈
    annotated_frame = draw_detections(frame, results)
    
    # 5. 表示または保存（モードに基づく）
    display_frame(annotated_frame)
    
    # 6. ユーザー入力を処理
    process_keyboard_input()
    
    # 7. 統計を更新
    update_performance_metrics()
```

### 5.3 エラーハンドリング

#### 5.3.1 カメラエラー
- **カメラが見つからない**: エラーメッセージで正常終了
- **カメラ切断**: 再接続を試行、利用可能なカメラにフォールバック
- **フレーム読み取り失敗**: フレームをスキップ、処理継続

#### 5.3.2 モデルエラー
- **NCNN エクスポート失敗**: PyTorchモデルにフォールバック
- **モデル読み込み失敗**: 新しいモデルファイルをダウンロード
- **推論エラー**: フレームをスキップ、エラーをログ

#### 5.3.3 表示エラー
- **GUI利用不可**: ヘッドレスモードに自動切り替え
- **表示接続喪失**: ヘッドレスモードで継続
- **ウィンドウクローズ**: クリーンシャットダウン

<div style="page-break-after: always;"></div>

### 5.4 シャットダウンシーケンス

1. **ユーザー終了**: 'q'キーまたはウィンドウクローズ
2. **リソースクリーンアップ**: カメラを解放、ウィンドウを破棄
3. **統計サマリー**: 最終パフォーマンスメトリクスを表示
4. **ファイルクリーンアップ**: 該当する場合最終フレームを保存
5. **正常終了**: コマンドプロンプトに戻る

---

<div style="page-break-after: always;"></div>

## 6. データフロー

### 6.1 入力データフロー

```
Camera Feed → Frame Capture → Preprocessing → Model Inference
     ↓              ↓              ↓              ↓
640x480 RGB → NumPy Array → Normalized → YOLO Results
```

### 6.2 処理データフロー

```
YOLO Results → Filter People → Extract Boxes → Calculate Stats
      ↓              ↓              ↓              ↓
All Objects → Person Class → Coordinates → Count/FPS
```

### 6.3 出力データフロー

```
Processed Data → Frame Annotation → Display/Save → User Feedback
       ↓               ↓               ↓              ↓
Stats/Boxes → Visual Overlay → GUI/File → Console Log
```

---

<div style="page-break-after: always;"></div>

## 7. 設定オプション

### 7.1 ランタイム設定

```python
# 主要設定可能パラメータ
CONFIDENCE_THRESHOLD = 0.5      # 検出信頼度
CAMERA_INDEX = 1                # 優先カメラ
FRAME_WIDTH = 640               # カメラ解像度
FRAME_HEIGHT = 480
TARGET_FPS = 15                 # カメラフレームレート
SAVE_INTERVAL = 5               # 自動保存間隔（ヘッドレス）
DURATION_SECONDS = 0            # 実行時間制限（0 = 無制限）
```

### 7.2 パフォーマンス調整

```python
# Raspberry Pi最適化
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)    # 遅延を削減
model.export(format='ncnn')             # ARM最適化
frame_skip = 2                          # N番目のフレームごとに処理
```

### 7.3 環境変数

```bash
# 表示設定
DISPLAY=:0.0                    # X11ディスプレイ
SSH_CLIENT=<ip>                 # SSH接続インジケータ

# システムパス
HOME=/home/pi                   # ユーザーディレクトリ
PYTHONPATH=/usr/local/lib       # Pythonライブラリパス
```

---

<div style="page-break-after: always;"></div>

## 8. テスト戦略

### 8.1 単体テスト

#### 8.1.1 カメラ機能
- インデックス0-3でのカメラ検出テスト
- フレームキャプチャと設定の確認
- 利用できないカメラのエラーハンドリングテスト

#### 8.1.2 検出機能
- YOLOモデルの読み込みと推論テスト
- 人物分類精度の確認
- 信頼度閾値フィルタリングテスト

#### 8.1.3 表示機能
- GUIモード初期化テスト
- ヘッドレスモード動作確認
- 画像保存機能テスト

### 8.2 統合テスト

#### 8.2.1 エンドツーエンドパイプライン
- カメラ → 検出 → 表示 フルパイプライン
- 継続動作でのパフォーマンス
- リソース使用量監視

#### 8.2.2 プラットフォームテスト
- Raspberry Pi 3B V1.2互換性
- 汎用Linuxシステム互換性

### 8.3 パフォーマンステスト

#### 8.3.1 ベンチマークシナリオ
- 単一人物検出
- 複数人物（2-5人）検出
- 混雑シーンパフォーマンス
- 低照度条件

<div style="page-break-after: always;"></div>

#### 8.3.2 ストレステスト
- 24時間継続動作
- メモリリーク検出
- 熱パフォーマンス影響

---

<div style="page-break-after: always;"></div>

## 9. セキュリティ考慮事項

### 9.1 プライバシー保護
- **ローカル処理**: すべての検出はデバイス上で実行
- **ネットワークなし**: 外部サーバーへのデータ送信なし
- **画像保存**: ローカルファイルシステムのみ
- **アクセス制御**: 標準ファイルシステム権限

### 9.2 データセキュリティ
- **一時データ**: ビデオフレームはメモリ内で処理
- **保存画像**: ユーザー制御の保存操作
- **ログなし**: 個人データはログに記録されない
- **暗号化**: ファイルシステムレベルの暗号化サポート

### 9.3 システムセキュリティ
- **依存関係**: 検証済みパッケージソースを使用
- **更新**: 定期的セキュリティ更新推奨
- **アクセス**: 標準ユーザー権限で十分
- **ネットワーク**: 動作にネットワークアクセス不要

---

<div style="page-break-after: always;"></div>

## 10. メンテナンスとサポート

### 10.1 定期メンテナンス

#### 10.1.1 ソフトウェア更新
- **月次**: 依存関係更新チェック
- **四半期**: 新しいバージョンが利用可能な場合YOLOv11モデル更新
- **必要に応じて**: セキュリティパッチとバグ修正

#### 10.1.2 ハードウェアメンテナンス
- **週次**: カメラ接続チェック
- **月次**: ストレージ容量使用量監視
- **四半期**: システム温度とパフォーマンスチェック

### 10.2 トラブルシューティングガイド

#### 10.2.1 一般的な問題
```
問題: 低FPSパフォーマンス
解決: CPU使用率チェック、解像度削減、NCNN有効化

問題: カメラが検出されない
解決: 接続チェック、権限確認、異なるインデックス試行

問題: GUIモードで表示なし
解決: DISPLAY変数チェック、ヘッドレスモード試行

問題: 高メモリ使用量
解決: アプリケーション再起動、メモリリークチェック
```

#### 10.2.2 診断コマンド
```bash
# システム情報
python -c "import cv2; print(cv2.__version__)"
python -c "import platform; print(platform.platform())"

# カメラテスト
ls /dev/video*
v4l2-ctl --list-devices

# パフォーマンス監視
htop
free -h
df -h
```

### 10.3 サポートリソース

- **ドキュメント**: この機能設計文書
- **コードコメント**: ソースコード内のインライン文書
- **エラーメッセージ**: 説明的コンソール出力
- **コミュニティ**: UltralyticsとOpenCVコミュニティ

---

<div style="page-break-after: always;"></div>

## 11. 将来の拡張

### 11.1 計画機能

#### 11.1.1 拡張検出
- **マルチオブジェクト**: 車、自転車、動物の検出
- **オブジェクト追跡**: フレーム間での個人追跡
- **ゾーン検出**: 検出エリアの定義
- **アラートシステム**: 検出イベントの通知

#### 11.1.2 パフォーマンス改善
- **モデル最適化**: より高速推論のための量子化
- **マルチスレッド**: 並列処理パイプライン
- **ハードウェア加速**: GPU/NPUサポート
- **適応品質**: 動的解像度調整

#### 11.1.3 ユーザーインターフェース
- **Webインターフェース**: ブラウザベースコントロールパネル
- **モバイルアプリ**: リモート監視機能
- **設定GUI**: ランタイムパラメータ調整
- **ダッシュボード**: 履歴統計とトレンド

### 11.2 技術ロードマップ

#### 11.2.1 短期（3ヶ月）
- バグ修正と安定性改善
- 追加カメラ形式サポート
- 拡張エラー回復
- パフォーマンス最適化

#### 11.2.2 中期（6ヶ月）
- Webベースインターフェース
- データベース統合
- 高度分析
- リモート監視

#### 11.2.3 長期（12ヶ月）
- エッジAI統合
- クラウド接続オプション
- 機械学習改善
- 商用展開機能

---

<div style="page-break-after: always;"></div>

## 12. 結論

この機能設計文書は、Raspberry Piプラットフォーム用に最適化されたリアルタイム物体検出システムの包括的概要を提供します。システムは、教育と研究アプリケーションのためのシンプルさを維持しながら、パフォーマンス、精度、使いやすさのバランスを成功させています。

### 主要成果
- リソース制約ハードウェアでのリアルタイム人物検出
- 異なる展開環境へのスマート適応
- 堅牢なエラーハンドリングと回復メカニズム
- 包括的パフォーマンス監視
- 最小設定でのユーザーフレンドリー操作

### 設計哲学
システムは以下を優先します：
1. **信頼性**: 様々な条件での堅牢な動作
2. **パフォーマンス**: Raspberry Piハードウェア用最適化
3. **使いやすさ**: 最小セットアップと直感的操作
4. **拡張性**: 将来の拡張のためのクリーンアーキテクチャ
5. **プライバシー**: 外部依存関係なしのローカル処理

この機能設計は、物体検出システムの実装、テスト、将来の開発の基盤として機能します。

---

<p align="center">
<strong>文書管理</strong><br>
<strong>バージョン:</strong> 1.0<br>
<strong>ステータス:</strong>最終ドラフト<br>
<strong>レビュー日:</strong>2025年10月<br>
<strong>次回レビュー:</strong><br> 
<strong>承認:</strong>技術レビュー待ち
</p>

---

<p align="center">
<em>文書終了</em>
</p>