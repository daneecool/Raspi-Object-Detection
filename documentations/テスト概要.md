# テスト概要

```bash
comas@raspi:~ $ source raspi/bin/activate
(raspi) comas@raspi:~ $ python3 test_raspi_detection.py

======================================================================
🍓 RASPBERRY PI 3B v1.2 OBJECT DETECTION TEST SUITE
======================================================================
Setting up Pi-optimized test environment...
Platform: Linux-6.12.47+rpt-rpi-v8-aarch64-with-glibc2.41
Architecture: aarch64
Python: 3.13.5
Total RAM: 0.9 GB
Available RAM: 0.6 GB
✅ Running on Raspberry Pi
✓ Pi test configuration loaded
----------------------------------------------------------------------
test_01_pi_environment_check (__main__.TestRaspberryPiDetection.test_01_pi_environment_check)
Test 1: Verify Pi environment and dependencies ...
🔧 Test 1: Pi Environment Check
------------------------------
✓ Architecture: aarch64
✓ OpenCV: 4.12.0
✓ Memory: 0.9GB (Pi constraint verified)
✓ CPU cores: 4
Test 1 PASSED: Pi environment verified (Time: 0.00s)
ok
test_02_ultralytics_import_optimized (__main__.TestRaspberryPiDetection.test_02_ultralytics_import_optimized)
Test 2: Test YOLO import with memory monitoring ...
📦 Test 2: Ultralytics Import (Memory Optimized)
---------------------------------------------
Initial memory: 248.9 MB
✓ Import time: 0.00 seconds
✓ Memory after import: 248.9 MB
✓ Import memory increase: 0.0 MB
Test 2 PASSED: Ultralytics import verified (Time: 0.00s)
ok
test_03_model_loading_pi_optimized (__main__.TestRaspberryPiDetection.test_03_model_loading_pi_optimized)
Test 3: Model loading with Pi memory constraints ...
🤖 Test 3: Model Loading (Pi Optimized)
-----------------------------------
Memory before model load: 248.9 MB
✓ Model load time: 0.45 seconds
✓ Memory after model: 265.0 MB
✓ Model memory increase: 16.1 MB
Test 3 PASSED: Model loading verified for Pi (Time: 0.78s)
ok
test_04_camera_detection_pi (__main__.TestRaspberryPiDetection.test_04_camera_detection_pi)
Test 4: Camera detection on Pi ...
📷 Test 4: Camera Detection (Pi)
-------------------------
✓ Camera detected
✓ Camera resolution: 640.0x480.0
✓ Frame captured: (480, 640, 3)
Test 4 PASSED: Camera detection checked (Time: 0.48s)
ok
test_05_inference_speed_pi (__main__.TestRaspberryPiDetection.test_05_inference_speed_pi)
Test 5: Inference speed test optimized for Pi ...
⚡ Test 5: Inference Speed (Pi Optimized)
-----------------------------------
Warming up model...
Running Pi inference speed test...
  Run 1: 3946.3ms
  Run 2: 3201.3ms
  Run 3: 3210.8ms
  Run 4: 3927.4ms
  Run 5: 2896.7ms
✓ Average inference: 3436.5ms
✓ Min time: 2896.7ms
✓ Max time: 3946.3ms
✓ Estimated FPS: 0.3
Test 5 PASSED: Pi inference speed verified (Time: 24.72s)
ok
test_06_memory_stress_pi (__main__.TestRaspberryPiDetection.test_06_memory_stress_pi)
Test 6: Memory stress test for Pi constraints ...
💾 Test 6: Memory Stress (Pi Constraints)
-----------------------------------
Initial memory: 304.9 MB
Running Pi memory stress test...
  Iteration 1: 311.9 MB
  Iteration 4: 305.5 MB
  Iteration 7: 305.5 MB
  Iteration 10: 305.5 MB
✓ Peak memory: 311.9 MB
✓ Memory increase: 7.0 MB
✓ Final memory: 305.5 MB
Test 6 PASSED: Pi memory constraints verified (Time: 35.92s)
ok
test_07_obj_detection_integration (__main__.TestRaspberryPiDetection.test_07_obj_detection_integration)
Test 7: Integration test with actual obj_detection.py ...
🔗 Test 7: obj_detection.py Integration
-----------------------------------
OpenCV version: 4.12.0
Platform: Linux-6.12.47+rpt-rpi-v8-aarch64-with-glibc2.41
Python version: 3.13.5
  Running on Raspberry Pi
  Device: Raspberry Pi 3 Model B Rev 1.2
Loading YOLO11n model...
Exporting model to NCNN format for Raspberry Pi optimization...
Ultralytics 8.3.217 🚀 Python-3.13.5 torch-2.9.0+cpu CPU (aarch64)
YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs

PyTorch: starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)

ONNX: starting export with onnx 1.19.1 opset 22...
ONNX: slimming with onnxslim 0.1.71...
2025-10-22 17:19:47.439364738 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: "/sys/class/drm/card0/device/vendor"
ONNX: export success ✅ 17.8s, saved as 'yolo11n.onnx' (10.2 MB)

NCNN: starting export with NCNN 1.0.20250916...
NCNN: running '/home/comas/raspi/lib/python3.13/site-packages/ultralytics/pnnx yolo11n.onnx ncnnparam=yolo11n_ncnn_model/model.ncnn.param ncnnbin=yolo11n_ncnn_model/model.ncnn.bin ncnnpy=yolo11n_ncnn_model/model_ncnn.py pnnxparam=yolo11n_ncnn_model/model.pnnx.param pnnxbin=yolo11n_ncnn_model/model.pnnx.bin pnnxpy=yolo11n_ncnn_model/model_pnnx.py pnnxonnx=yolo11n_ncnn_model/model.pnnx.onnx fp16=0 device=cpu inputshape="[1, 3, 640, 640]"'
pnnxparam = yolo11n_ncnn_model/model.pnnx.param
pnnxbin = yolo11n_ncnn_model/model.pnnx.bin
pnnxpy = yolo11n_ncnn_model/model_pnnx.py
pnnxonnx = yolo11n_ncnn_model/model.pnnx.onnx
ncnnparam = yolo11n_ncnn_model/model.ncnn.param
ncnnbin = yolo11n_ncnn_model/model.ncnn.bin
ncnnpy = yolo11n_ncnn_model/model_ncnn.py
fp16 = 0
optlevel = 2
device = cpu
inputshape = [1,3,640,640]f32
inputshape2 =
customop =
moduleop =
get inputshape from traced inputs
inputshape = [1,3,640,640]f32
inputshape2 =
############# pass_level0 onnx
inline_containers ...                 0.01ms
eliminate_noop ...                    2.39ms
fold_constants ...                    1.62ms
canonicalize ...                      4.05ms
shape_inference ...                4010.85ms
fold_constants_dynamic_shape ...      5.56ms
inline_if_graph ...                   1.00ms
fuse_constant_as_attribute ...       31.96ms
eliminate_noop_with_shape ...         5.61ms
┌──────────────────┬──────────┬──────────┐
│                  │ orig     │ opt      │
├──────────────────┼──────────┼──────────┤
│ node             │ 320      │ 320      │
│ initializer      │ 196      │ 186      │
│ functions        │ 0        │ 0        │
├──────────────────┼──────────┼──────────┤
│ nn module op     │ 0        │ 0        │
│ custom module op │ 0        │ 0        │
│ aten op          │ 0        │ 0        │
│ prims op         │ 0        │ 0        │
│ onnx native op   │ 320      │ 320      │
├──────────────────┼──────────┼──────────┤
│ Add              │ 16       │ 16       │
│ Concat           │ 23       │ 23       │
│ Conv             │ 88       │ 88       │
│ Div              │ 1        │ 1        │
│ MatMul           │ 2        │ 2        │
│ MaxPool          │ 3        │ 3        │
│ Mul              │ 79       │ 79       │
│ Reshape          │ 8        │ 8        │
│ Resize           │ 2        │ 2        │
│ Sigmoid          │ 78       │ 78       │
│ Slice            │ 2        │ 2        │
│ Softmax          │ 2        │ 2        │
│ Split            │ 11       │ 11       │
│ Sub              │ 2        │ 2        │
│ Transpose        │ 3        │ 3        │
└──────────────────┴──────────┴──────────┘
############# pass_level1 onnx
############# pass_level2
############# pass_level3
open failed
############# pass_level4
############# pass_level5
############# pass_ncnn
NCNN: export success ✅ 9.0s, saved as 'yolo11n_ncnn_model' (10.2 MB)

Export complete (38.3s)
Results saved to /home/comas
Predict:         yolo predict task=detect model=yolo11n_ncnn_model imgsz=640
Validate:        yolo val task=detect model=yolo11n_ncnn_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml
Visualize:       https://netron.app
 Model exported to NCNN format successfully
WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.
 NCNN model loaded successfully
Testing camera connection...
Attempting to connect to camera 1...
[ WARN:0@113.017] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video1): can't open camera by index
[ERROR:0@113.150] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
 Camera 1 not available, trying camera 0...
Check Camera 0 connected successfully
Resolution: 640x480
FPS: 15.0
 Camera test successful - will use camera 0

============================================================
 STARTING OBJECT DETECTION
============================================================
✓ Pi detection result: True
✓ Detection info: Raspberry Pi 3 Model B Rev 1.2
✓ obj_detection.py integration working
Test 7 PASSED: Integration test completed (Time: 38.99s)
ok
test_08_pi_performance_benchmark (__main__.TestRaspberryPiDetection.test_08_pi_performance_benchmark)
Test 8: Overall Pi performance benchmark ...
📊 Test 8: Pi Performance Benchmark
------------------------------
CPU usage: 2.8%
Memory usage: 52.0%
Available memory: 434.5 MB
✓ Single inference: 4826.7ms
✓ Final CPU: 32.1%
✓ Final memory: 51.4%
Test 8 PASSED: Pi performance benchmark completed (Time: 6.92s)
ok

======================================================================
🍓 RASPBERRY PI TEST SUITE COMPLETED
======================================================================
 Pi-Optimized Test Summary:
  ✓ Test 1: Pi Environment Check — 0.00s
  ✓ Test 2: Ultralytics Import (Memory Optimized) — 0.00s
  ✓ Test 3: Model Loading (Pi Optimized) — 0.78s
  ✓ Test 4: Camera Detection (Pi) — 0.48s
  ✓ Test 5: Inference Speed (Pi Optimized) — 24.72s
  ✓ Test 6: Memory Stress (Pi Constraints) — 35.92s
  ✓ Test 7: obj_detection.py Integration — 38.99s
  ✓ Test 8: Pi Performance Benchmark — 6.92s

 🎯 Your obj_detection.py is ready for Raspberry Pi 3B v1.2!
======================================================================

----------------------------------------------------------------------
Ran 8 tests in 108.718s

OK

```